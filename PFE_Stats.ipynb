{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import re   \n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data\n",
    "it_data = pd.read_csv(\"data/QueryResults.csv\")\n",
    "it_data = it_data.drop('Count', 1)\n",
    "it_data = it_data.head(2000)\n",
    "stopWords_fr = set(stopwords.words('french'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if a word is a technology\n",
    "def check_word_technology(tech):\n",
    "    word = get_cleaned_hashtags(tech)\n",
    "    tech = tech.lower()\n",
    "    if tech in it_data['TagName'].values:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "#get the name of the company\n",
    "def extract_company_name(email):\n",
    "    email = email.split('@')\n",
    "    company_website = email[1].split('.')\n",
    "    return company_website[0]\n",
    "\n",
    "#get the list of all included emails in the offer\n",
    "def get_emails_list(text):\n",
    "    return re.findall('\\S+@\\S+', text) \n",
    "\n",
    "#clean all hashtags\n",
    "def get_cleaned_hashtags(text):\n",
    "    hashtags = re.findall('#\\S+', text)\n",
    "    cleaned = []\n",
    "    for hashtag in hashtags:\n",
    "        curr = hashtag[1:]\n",
    "        cleaned.append(curr)\n",
    "    return cleaned\n",
    "\n",
    "def contains_word(s, w):\n",
    "    return f' {w} ' in f' {s} '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Technologies\n",
      "\n",
      "{'java', 'dotnet', 'web'}\n",
      "\n",
      "--------------company: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------Technologies\\n\")\n",
    "technologies = set()        \n",
    "for word in it_data['TagName'].values:\n",
    "    if contains_word(annonce, word):\n",
    "        technologies.add(word)\n",
    "\n",
    "print(technologies)\n",
    "\n",
    "   \n",
    "print(\"\\n--------------company: \\n\")\n",
    "emails = get_emails_list(annonce)\n",
    "emails = get_emails_list(annonce)\n",
    "for email in emails:\n",
    "    print(extract_company_name(email))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = []\n",
    "path = \"offers\"\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "            files.append(os.path.join(r, file))\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_comp = pd.DataFrame(columns=['Technology','Company'])\n",
    "\n",
    "\n",
    "for file in files:\n",
    "    f = open(file, \"r\", encoding=\"latin-1\")\n",
    "    annonce = f.read()\n",
    "    \n",
    "    #Extracting company names\n",
    "    \n",
    "    emails = get_emails_list(annonce)\n",
    "    email_list = set()\n",
    "    for email in emails:\n",
    "        email_list.add(extract_company_name(email))\n",
    "    \n",
    "    \n",
    "    if len(email_list) == 0:\n",
    "        email = \"Unknown\"\n",
    "    else:\n",
    "        email_list = sorted(email_list)\n",
    "        email = email_list[0]\n",
    "        \n",
    "        \n",
    "    #Extracting Technologies - Removing punctuation - Removing French stopwrds considered as technologies\n",
    "    \n",
    "    annonce = annonce.lower()\n",
    "    tokens = nltk.word_tokenize(annonce)\n",
    "    annonce = re.sub(r'[^\\w\\s]','',annonce)\n",
    "    technologies = set()        \n",
    "    for word in it_data['TagName'].values:\n",
    "        if word not in stopWords_fr and contains_word(annonce, word):\n",
    "            technologies.add(word)\n",
    "            \n",
    "    for techno in technologies:\n",
    "        #print(email, techno)\n",
    "        tech_comp = tech_comp.append({'Technology': techno,'Company':email}, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "java                 22\n",
       "web                  21\n",
       "sap                  14\n",
       "mobile               12\n",
       "cloud                12\n",
       "sql                  11\n",
       "jee                  11\n",
       "angular              10\n",
       "javascript            9\n",
       "machine learning      8\n",
       "python                8\n",
       "php                   8\n",
       "oracle                7\n",
       "dotnet                7\n",
       "devops                7\n",
       "salesforce            6\n",
       "html                  5\n",
       "stack                 5\n",
       "android               5\n",
       "product               5\n",
       "this                  4\n",
       "server                4\n",
       "unique                4\n",
       "email                 4\n",
       "api                   4\n",
       "data science          4\n",
       "blockchain            4\n",
       "performance           4\n",
       "excel                 4\n",
       "cgi                   4\n",
       "                     ..\n",
       "computer science      1\n",
       "algorithm             1\n",
       "distance              1\n",
       "swift                 1\n",
       "powerbi               1\n",
       "tensorflow            1\n",
       "transform             1\n",
       "kotlin                1\n",
       "excel vba             1\n",
       "postgresql            1\n",
       "focus                 1\n",
       "microservices         1\n",
       "model                 1\n",
       "ssis                  1\n",
       "automation            1\n",
       "types                 1\n",
       "hadoop                1\n",
       "laravel               1\n",
       "statistics            1\n",
       "rest                  1\n",
       "linux                 1\n",
       "mongodb               1\n",
       "elasticsearch         1\n",
       "simulation            1\n",
       "jdbc                  1\n",
       "azure devops          1\n",
       "responsive design     1\n",
       "validation            1\n",
       "unix                  1\n",
       "embedded              1\n",
       "Name: Technology, Length: 157, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tech_comp.head()\n",
    "tech_comp['Technology'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgats\n",
      "smarteez\n",
      "confidentiel\n"
     ]
    }
   ],
   "source": [
    "company_emails = []\n",
    "for file in files:\n",
    "    f = open(file, \"r\", encoding=\"latin-1\")\n",
    "    annonce = f.read()\n",
    "    emails = get_emails_list(annonce)\n",
    "    email_list = set()\n",
    "    for email in emails:\n",
    "        email_list.add(extract_company_name(email))\n",
    "    sorted(email_list)\n",
    "    company_emails.append(email_list)\n",
    "    \n",
    "for lst in company_emails:\n",
    "    sorted(lst)\n",
    "    if len(lst) == 2:\n",
    "        lst = sorted(lst)\n",
    "        print(lst[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
